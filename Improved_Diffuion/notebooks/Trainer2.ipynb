{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Optimizer\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Callable\n",
    "from src.gaussian_diffusion import GaussianDiffusion\n",
    "\n",
    "class DiffusionTrainingSystem:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        diffusion: GaussianDiffusion,\n",
    "        dataset: Dataset,\n",
    "        device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        batch_size: int = 64,\n",
    "        optimizer_class: type = AdamW,\n",
    "        lr: float = 3e-4,\n",
    "        grad_clip: float = 1.0,\n",
    "        save_dir: str = \"saved_models\",\n",
    "        save_interval: int = 50,\n",
    "        data_preprocess_fn: Optional[Callable] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        扩散模型训练系统\n",
    "\n",
    "        参数:\n",
    "            model: 待训练的UNet模型\n",
    "            diffusion: 扩散过程处理器\n",
    "            dataset: 原始数据集对象\n",
    "            device: 训练设备\n",
    "            batch_size: 批次大小\n",
    "            optimizer_class: 优化器类型\n",
    "            lr: 初始学习率\n",
    "            grad_clip: 梯度裁剪阈值\n",
    "            save_dir: 模型保存路径\n",
    "            save_interval: 检查点保存间隔\n",
    "            data_preprocess_fn: 自定义数据预处理函数\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.diffusion = diffusion.to(device)\n",
    "        self.grad_clip = grad_clip\n",
    "        self.save_dir = save_dir\n",
    "        self.save_interval = save_interval\n",
    "\n",
    "        # 数据预处理流水线\n",
    "        self.processed_data = self._prepare_data(dataset, data_preprocess_fn)\n",
    "\n",
    "        # 优化器配置\n",
    "        self.optimizer = optimizer_class(self.model.parameters(), lr=lr)\n",
    "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=1000)  # 可配置化\n",
    "\n",
    "        # 训练状态\n",
    "        self.epoch = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.loss_history = {'train': []}\n",
    "\n",
    "        # 创建保存目录\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def _prepare_data(self, dataset: Dataset, preprocess_fn: Optional[Callable]) -> DataLoader:\n",
    "        \"\"\"数据预处理与加载器构建\"\"\"\n",
    "        # 自动提取特征和标签\n",
    "        features, labels = [], []\n",
    "        for data in dataset:\n",
    "            features.append(data.x)\n",
    "            labels.append(data.y)\n",
    "\n",
    "        # 转换为张量并添加通道维度\n",
    "        features = torch.stack(features).unsqueeze(1)  # [N, 1, H, W]\n",
    "        labels = torch.stack(labels)\n",
    "\n",
    "        # 自定义预处理\n",
    "        if preprocess_fn is not None:\n",
    "            features, labels = preprocess_fn(features, labels)\n",
    "\n",
    "        # 构建数据加载器\n",
    "        tensor_dataset = TensorDataset(features.to(self.device), labels.to(self.device))\n",
    "        return DataLoader(tensor_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "    def _training_step(self, batch: tuple) -> dict:\n",
    "        \"\"\"单批次训练逻辑\"\"\"\n",
    "        x_batch, label_batch = batch\n",
    "        B = x_batch.size(0)\n",
    "\n",
    "        # 时间步采样\n",
    "        t = torch.randint(0, self.diffusion.num_steps, (B,), device=self.device).long()\n",
    "\n",
    "        # 扩散损失计算\n",
    "        losses = self.diffusion.training_losses(\n",
    "            model=self.model,\n",
    "            x_start=x_batch,\n",
    "            t=t,\n",
    "            batch_labels=label_batch\n",
    "        )\n",
    "\n",
    "        # 反向传播\n",
    "        self.optimizer.zero_grad()\n",
    "        losses['loss'].mean().backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return {k: v.mean().item() for k, v in losses.items()}\n",
    "\n",
    "    def _save_checkpoint(self, is_best: bool = False):\n",
    "        \"\"\"保存训练状态\"\"\"\n",
    "        state = {\n",
    "            'epoch': self.epoch,\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'loss': self.loss_history['train'][-1],\n",
    "            'best_loss': self.best_loss\n",
    "        }\n",
    "\n",
    "        filename = 'best_model.pth' if is_best else f'checkpoint_epoch_{self.epoch}.pth'\n",
    "        torch.save(state, os.path.join(self.save_dir, filename))\n",
    "\n",
    "    def _visualize_progress(self):\n",
    "        \"\"\"训练过程可视化\"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        plt.subplot(121)\n",
    "        plt.plot(self.loss_history['train'], label='Training Loss')\n",
    "        plt.title(\"Loss Curve\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.plot(self.loss_history.get('val', []), label='Validation Loss', color='orange')\n",
    "        plt.title(\"Validation Metrics\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.save_dir, 'training_progress.png'))\n",
    "        plt.close()\n",
    "\n",
    "    def train(self, num_epochs: int, enable_progress_bar: bool = True):\n",
    "        \"\"\"完整训练流程\"\"\"\n",
    "        for _ in range(num_epochs):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0.0\n",
    "            progress_bar = tqdm(self.processed_data, desc=f\"Epoch {self.epoch+1}\") if enable_progress_bar else self.processed_data\n",
    "\n",
    "            for batch in progress_bar:\n",
    "                step_metrics = self._training_step(batch)\n",
    "                epoch_loss += step_metrics['loss']\n",
    "\n",
    "                if enable_progress_bar:\n",
    "                    progress_bar.set_postfix({k: f\"{v:.4f}\" for k, v in step_metrics.items()})\n",
    "\n",
    "            # 记录与更新\n",
    "            avg_loss = epoch_loss / len(self.processed_data)\n",
    "            self.loss_history['train'].append(avg_loss)\n",
    "            self.scheduler.step()\n",
    "\n",
    "            # 模型保存逻辑\n",
    "            if avg_loss < self.best_loss:\n",
    "                self.best_loss = avg_loss\n",
    "                self._save_checkpoint(is_best=True)\n",
    "\n",
    "            if (self.epoch + 1) % self.save_interval == 0:\n",
    "                self._save_checkpoint()\n",
    "                self._visualize_progress()\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path: str):\n",
    "        \"\"\"加载训练状态\"\"\"\n",
    "        state = torch.load(checkpoint_path, map_location=self.device)\n",
    "        self.model.load_state_dict(state['model'])\n",
    "        self.optimizer.load_state_dict(state['optimizer'])\n",
    "        self.epoch = state['epoch']\n",
    "        self.best_loss = state['best_loss']\n",
    "        print(f\"Loaded checkpoint from epoch {self.epoch} with loss {state['loss']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
