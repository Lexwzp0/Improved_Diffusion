{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-17T12:33:51.994345Z",
     "start_time": "2025-03-17T12:33:51.988852Z"
    }
   },
   "source": [
    "import torch\n",
    "from src.gaussian_diffusion import GaussianDiffusion\n",
    "from src.Unet import ConditionalDiffusionUNet\n",
    "from src.classifier import UNetClassifier"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T12:33:52.195111Z",
     "start_time": "2025-03-17T12:33:52.023374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 参数配置\n",
    "num_classes = 7  # 根据实际类别数修改\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载模型 -------------------------------------------------\n",
    "unet = ConditionalDiffusionUNet(num_classes=num_classes, time_dim=128, label_dim=64).to(device)\n",
    "unet.load_state_dict(torch.load(\"best_unet.pth\", map_location=device))\n",
    "\n",
    "classifier = UNetClassifier(num_classes).to(device)\n",
    "classifier.load_state_dict(torch.load(\"best_noisy_classifier.pth\", map_location=device))\n",
    "classifier.eval()\n",
    "\n",
    "# 初始化扩散模型 --------------------------------------------\n",
    "diffusion = GaussianDiffusion(\n",
    "    num_steps=64,\n",
    "    model=unet,\n",
    "    classifier=classifier,\n",
    "    classifier_scale=1.0  # 调节引导强度\n",
    ").to(device)\n",
    "\n",
    "# 生成配置 -------------------------------------------------\n",
    "batch_size = 1\n",
    "target_labels = torch.tensor([0], device=device)  # 手动指定目标类别\n",
    "assert len(target_labels) == batch_size, \"标签数量需与批次大小一致\"\n",
    "\n",
    "# 执行生成 -------------------------------------------------\n",
    "generated = diffusion.p_sample_loop(\n",
    "    shape=(batch_size, 1, 24, 50),\n",
    "    batch_labels=target_labels,\n",
    "    noise=None,  # 可传入自定义噪声\n",
    "    clip_denoised=True,\n",
    "    progress=True\n",
    ")\n",
    "\n",
    "# 结果验证 -------------------------------------------------\n",
    "print(\"生成样本范围:\", generated.min().item(), \"~\", generated.max().item())  # 应在[-1,1]之间\n",
    "\n",
    "# 分类验证（可选）------------------------------------------\n",
    "with torch.no_grad():\n",
    "    logits = classifier(generated, torch.zeros(batch_size, device=device).long())\n",
    "    preds = logits.argmax(dim=1)\n",
    "    accuracy = (preds == target_labels).float().mean()\n",
    "    print(f\"生成样本分类准确率: {accuracy.item():.2%}\")\n"
   ],
   "id": "39c699a0cbf98293",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_unet.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m# 加载模型 -------------------------------------------------\u001B[39;00m\n\u001B[32m      6\u001B[39m unet = ConditionalDiffusionUNet(num_classes=num_classes, time_dim=\u001B[32m128\u001B[39m, label_dim=\u001B[32m64\u001B[39m).to(device)\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m unet.load_state_dict(\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mbest_unet.pth\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m      9\u001B[39m classifier = UNetClassifier(num_classes).to(device)\n\u001B[32m     10\u001B[39m classifier.load_state_dict(torch.load(\u001B[33m\"\u001B[39m\u001B[33mbest_noisy_classifier.pth\u001B[39m\u001B[33m\"\u001B[39m, map_location=device))\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\serialization.py:1425\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[39m\n\u001B[32m   1422\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mencoding\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args.keys():\n\u001B[32m   1423\u001B[39m     pickle_load_args[\u001B[33m\"\u001B[39m\u001B[33mencoding\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1425\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[32m   1426\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[32m   1427\u001B[39m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[32m   1428\u001B[39m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[32m   1429\u001B[39m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[32m   1430\u001B[39m         orig_position = opened_file.tell()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\serialization.py:751\u001B[39m, in \u001B[36m_open_file_like\u001B[39m\u001B[34m(name_or_buffer, mode)\u001B[39m\n\u001B[32m    749\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[32m    750\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[32m--> \u001B[39m\u001B[32m751\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    752\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    753\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\serialization.py:732\u001B[39m, in \u001B[36m_open_file.__init__\u001B[39m\u001B[34m(self, name, mode)\u001B[39m\n\u001B[32m    731\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[32m--> \u001B[39m\u001B[32m732\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'best_unet.pth'"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
