{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:23.605587Z",
     "start_time": "2025-03-15T06:49:13.259516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from data.pyg_dataToGraph import DataToGraph\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt"
   ],
   "id": "e4ec8ecba7d669e6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 热力图",
   "id": "cdf162143d0202e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:23.630140Z",
     "start_time": "2025-03-15T06:49:23.613770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def heatmap(numpy_array):\n",
    "    # 绘制热力图\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(numpy_array, cmap='viridis', aspect='auto', vmin=-1, vmax=1)  # 调整颜色范围以更好地显示小值\n",
    "    plt.colorbar(label='Value', extend='max')  # 颜色条\n",
    "    plt.title('Tensor Visualization (Heatmap)')\n",
    "    plt.xlabel('Column Index')\n",
    "    plt.ylabel('Row Index')\n",
    "    plt.xticks(range(0, numpy_array.shape[1], 5))  # 设置 x 轴刻度\n",
    "    plt.yticks(range(0, numpy_array.shape[0], 1))  # 设置 y 轴刻度（密集）\n",
    "    plt.ylim(0, numpy_array.shape[0] - 1)  # 调整 y 轴范围\n",
    "\n",
    "    # 绘制网格线\n",
    "    plt.grid(which='both', axis='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "e8401a51dd91a291",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.539924Z",
     "start_time": "2025-03-15T06:49:24.056060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO 加载数据集\n",
    "dataset = DataToGraph(\n",
    "    raw_data_path='../../data/',\n",
    "    dataset_name='TFF' + '.mat')  # 格式: [(graph,label),...,(graph,label)]\n",
    "\n",
    "input_dim = dataset[0].x.size(1)\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "# 提取所有的x和y\n",
    "x0 = []\n",
    "labels = []\n",
    "\n",
    "for data in dataset:\n",
    "    # 提取x (形状为 [num_nodes, input_dim])\n",
    "    # 但是你提到dataset.x的形状是 [24,50]，这可能是一个图的x特征矩阵\n",
    "    x0.append(data.x)\n",
    "    # 提取y（标量标签）\n",
    "    labels.append(data.y)\n",
    "\n",
    "# 将列表转换为张量\n",
    "x0 = torch.stack(x0)  # 形状 [num_samples, 24, 50]\n",
    "labels = torch.stack(labels)  # 形状 [num_samples]\n",
    "\n",
    "print(num_classes)\n",
    "print(\"X0 shape:\", x0.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ],
   "id": "9093667bb5e35cef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/TFF.mat'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:39\u001B[39m, in \u001B[36m_open_file\u001B[39m\u001B[34m(file_like, appendmat, mode)\u001B[39m\n\u001B[32m     38\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     41\u001B[39m     \u001B[38;5;66;03m# Probably \"not found\"\u001B[39;00m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '../../data/TFF.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# TODO 加载数据集\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m dataset = \u001B[43mDataToGraph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mraw_data_path\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m../../data/\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mTFF\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m.mat\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 格式: [(graph,label),...,(graph,label)]\u001B[39;00m\n\u001B[32m      6\u001B[39m input_dim = dataset[\u001B[32m0\u001B[39m].x.size(\u001B[32m1\u001B[39m)\n\u001B[32m      7\u001B[39m num_classes = dataset.num_classes\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Learn\\Improved_Diffuion\\data\\pyg_dataToGraph.py:18\u001B[39m, in \u001B[36mDataToGraph.__init__\u001B[39m\u001B[34m(self, raw_data_path, dataset_name, transform, pre_transform, pre_filter)\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28mself\u001B[39m.raw_data_path = raw_data_path\n\u001B[32m     17\u001B[39m \u001B[38;5;28mself\u001B[39m.dataset_name = dataset_name\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mDataToGraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mraw_data_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_transform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_filter\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch_geometric\\data\\dataset.py:115\u001B[39m, in \u001B[36mDataset.__init__\u001B[39m\u001B[34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001B[39m\n\u001B[32m    112\u001B[39m     \u001B[38;5;28mself\u001B[39m._download()\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.has_process:\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch_geometric\\data\\dataset.py:262\u001B[39m, in \u001B[36mDataset._process\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    259\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mProcessing...\u001B[39m\u001B[33m'\u001B[39m, file=sys.stderr)\n\u001B[32m    261\u001B[39m fs.makedirs(\u001B[38;5;28mself\u001B[39m.processed_dir, exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m262\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    264\u001B[39m path = osp.join(\u001B[38;5;28mself\u001B[39m.processed_dir, \u001B[33m'\u001B[39m\u001B[33mpre_transform.pt\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    265\u001B[39m fs.torch_save(_repr(\u001B[38;5;28mself\u001B[39m.pre_transform), path)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Learn\\Improved_Diffuion\\data\\pyg_dataToGraph.py:30\u001B[39m, in \u001B[36mDataToGraph.process\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mprocess\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m     29\u001B[39m     \u001B[38;5;66;03m# 将数据处理为图列表和标签列表\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m     data = \u001B[43mio\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloadmat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m.\u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mraw_data_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     31\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dataset_name == \u001B[33m'\u001B[39m\u001B[33mNPS_64sensors_13type.mat\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dataset_name == \u001B[33m'\u001B[39m\u001B[33mTFF.mat\u001B[39m\u001B[33m'\u001B[39m:\n\u001B[32m     32\u001B[39m         x_set = numpy.concatenate((data[\u001B[33m'\u001B[39m\u001B[33mx_train\u001B[39m\u001B[33m'\u001B[39m], data[\u001B[33m'\u001B[39m\u001B[33mx_test\u001B[39m\u001B[33m'\u001B[39m]), axis=\u001B[32m2\u001B[39m)  \u001B[38;5;66;03m# (D x V x N)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:233\u001B[39m, in \u001B[36mloadmat\u001B[39m\u001B[34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001B[39m\n\u001B[32m     88\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     89\u001B[39m \u001B[33;03mLoad MATLAB file.\u001B[39;00m\n\u001B[32m     90\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    230\u001B[39m \u001B[33;03m    3.14159265+3.14159265j])\u001B[39;00m\n\u001B[32m    231\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    232\u001B[39m variable_names = kwargs.pop(\u001B[33m'\u001B[39m\u001B[33mvariable_names\u001B[39m\u001B[33m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m233\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_open_file_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mappendmat\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    234\u001B[39m \u001B[43m    \u001B[49m\u001B[43mMR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmat_reader_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    235\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmatfile_dict\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mMR\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_variables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvariable_names\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\contextlib.py:137\u001B[39m, in \u001B[36m_GeneratorContextManager.__enter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    135\u001B[39m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args, \u001B[38;5;28mself\u001B[39m.kwds, \u001B[38;5;28mself\u001B[39m.func\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m137\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m    139\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mgenerator didn\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt yield\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:17\u001B[39m, in \u001B[36m_open_file_context\u001B[39m\u001B[34m(file_like, appendmat, mode)\u001B[39m\n\u001B[32m     15\u001B[39m \u001B[38;5;129m@contextmanager\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_open_file_context\u001B[39m(file_like, appendmat, mode=\u001B[33m'\u001B[39m\u001B[33mrb\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     f, opened = \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mappendmat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     18\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     19\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m f\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:45\u001B[39m, in \u001B[36m_open_file\u001B[39m\u001B[34m(file_like, appendmat, mode)\u001B[39m\n\u001B[32m     43\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m appendmat \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m file_like.endswith(\u001B[33m'\u001B[39m\u001B[33m.mat\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m     44\u001B[39m         file_like += \u001B[33m'\u001B[39m\u001B[33m.mat\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     46\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     47\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[32m     48\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mReader needs file name or open file-like object\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     49\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '../../data/TFF.mat'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.541701200Z",
     "start_time": "2025-03-03T14:17:06.230027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将数据传输到GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TODO 确定超参数的值\n",
    "# 超参数值\n",
    "num_steps = 1000  # 假设扩散步数为 1000\n",
    "eps = 1e-5  # 避免除以零或引入过小的数值的小偏移量\n",
    "\n",
    "# 生成时间步的序列\n",
    "t = torch.linspace(0, 1, num_steps + 1)  # 主要时间步范围从 0 到 1\n",
    "\n",
    "# 使用余弦调度生成 betas\n",
    "betas = torch.cos(torch.pi / 2.0 * t) ** 2  # 余弦平方函数\n",
    "betas = betas / betas.max()  # 归一化到 0-1 范围\n",
    "betas = torch.flip(betas, [0])  # 反转顺序，以确保从小到大递增\n",
    "betas = torch.clamp(betas, min=1e-5, max=0.5e-2)  # 调整范围到 (1e-5, 0.5e-2)\n",
    "\n",
    "# 计算 alpha , alpha_prod , alpha_prod_previous , alpha_bar_sqrt 等变量的值\n",
    "alphas = 1 - betas\n",
    "alphas_prod = torch.cumprod(alphas, dim=0)  # 累积连乘\n",
    "alphas_prod_p = torch.cat([torch.tensor([1]).float(), alphas_prod[:-1]], 0)  # p means previous\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n",
    "\n",
    "# 将超参数也移动到GPU\n",
    "betas = betas.to(device)\n",
    "alphas = alphas.to(device)\n",
    "alphas_prod = alphas_prod.to(device)\n",
    "alphas_prod_p = alphas_prod_p.to(device)\n",
    "alphas_bar_sqrt = alphas_bar_sqrt.to(device)\n",
    "one_minus_alphas_bar_log = one_minus_alphas_bar_log.to(device)\n",
    "one_minus_alphas_bar_sqrt = one_minus_alphas_bar_sqrt.to(device)\n",
    "\n",
    "assert alphas_prod.shape == alphas_prod.shape == alphas_prod_p.shape \\\n",
    "       == alphas_bar_sqrt.shape == one_minus_alphas_bar_log.shape \\\n",
    "       == one_minus_alphas_bar_sqrt.shape\n",
    "print(\"all the same shape:\", betas.shape)"
   ],
   "id": "3ea5f3e71c540e11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the same shape: torch.Size([1001])\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.566716800Z",
     "start_time": "2025-03-03T14:17:06.276115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract(a, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)"
   ],
   "id": "25c902251fb7c1e5",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.567225800Z",
     "start_time": "2025-03-03T14:17:06.307556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def exists(x):\n",
    "    return x is not None"
   ],
   "id": "5d594623bd487587",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MySequential",
   "id": "5216475999168882"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.567225800Z",
     "start_time": "2025-03-03T14:17:06.331288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MySequential(nn.Sequential):\n",
    "    def forward(self, x, t_emb):\n",
    "        for module in self:\n",
    "            if isinstance(module, ConditionalBlock):  # 仅对特定模块传参\n",
    "                x = module(x, t_emb)\n",
    "            elif isinstance(module, MyBlock):\n",
    "                x = module(x, t_emb)\n",
    "            else:  # 其他模块按默认方式处理\n",
    "                x = module(x)\n",
    "        return x\n"
   ],
   "id": "52976f225c10993e",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TimeEmbedding",
   "id": "3a1415dddc917612"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.581937400Z",
     "start_time": "2025-03-03T14:17:06.343739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EnhancedTimeEmbedding(nn.Module):\n",
    "    \"\"\"增强时间嵌入（添加多层感知）\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Linear(dim, dim*4),\n",
    "            nn.GELU(),\n",
    "            #nn.SiLU(),\n",
    "            nn.Linear(dim*4, dim*4),\n",
    "            #nn.SiLU(),\n",
    "            #nn.Linear(dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.log(torch.tensor(10000)) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return self.embed(emb)"
   ],
   "id": "5a3e31fb304cd364",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test_time_embedding",
   "id": "3e96914fc9fa392d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.581937400Z",
     "start_time": "2025-03-03T14:17:06.363362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t = torch.randint(0, 1000, (64,))  # 时间步（如扩散步数）\n",
    "# t = torch.randint(0, time_steps, (batch_size,))  # 形状 [32]\n",
    "\n",
    "print(t)\n",
    "t_model = EnhancedTimeEmbedding(64)\n",
    "t_emb = t_model(t)\n",
    "print(t_emb.shape)\n",
    "print(t_emb.shape[1])"
   ],
   "id": "c15b52807f6b502b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([686,  84, 329, 211, 237, 412,   3, 297, 815, 323, 898, 812, 895, 907,\n",
      "        711, 638, 661, 354, 548, 660, 251, 798, 209, 954, 335, 680, 419, 542,\n",
      "        257, 135, 438, 119, 467, 738, 526, 445, 967, 821, 864, 582, 798, 661,\n",
      "        175, 894,  58, 651, 189, 684, 423, 970, 964, 767, 385, 227, 981, 338,\n",
      "        442, 893, 734, 275,   9, 814,  96,  94])\n",
      "torch.Size([64, 256])\n",
      "256\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ConditionalEmbedding",
   "id": "4c6575ddb8befca4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.581937400Z",
     "start_time": "2025-03-03T14:17:06.414760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "def sinusoidal_embedding(t, dim):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        t: 时间步张量 [batch_size, ]\n",
    "        dim: 嵌入维度\n",
    "    Returns:\n",
    "        嵌入向量 [batch_size, dim]\n",
    "    \"\"\"\n",
    "    device = t.device\n",
    "    half_dim = dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "    emb = t.float()[:, None] * emb[None, :]  # [batch_size, half_dim]\n",
    "\n",
    "    # 拼接正弦和余弦分量\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "\n",
    "    # 处理奇数维度情况\n",
    "    if dim % 2 == 1:\n",
    "        emb = F.pad(emb, (0, 1), mode='constant')\n",
    "\n",
    "    return emb\n"
   ],
   "id": "50476b60c3c2815a",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.592167900Z",
     "start_time": "2025-03-03T14:17:06.441828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConditionalEmbedding(nn.Module):\n",
    "    def __init__(self, num_classes, time_dim=256, label_dim=128):\n",
    "        super().__init__()\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(time_dim, time_dim*4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim*4, time_dim*4)\n",
    "        )\n",
    "        self.label_embed = nn.Embedding(num_classes, label_dim)\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(time_dim*4 + label_dim, time_dim*2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim*2, time_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        # t: [B,] 时间步\n",
    "        # y: [B,] 标签\n",
    "        t_emb = sinusoidal_embedding(t, self.time_embed[0].in_features)\n",
    "        t_emb = self.time_embed(t_emb)  # [B, time_dim]\n",
    "\n",
    "        l_emb = self.label_embed(y).squeeze(1)     # [B, label_dim]\n",
    "\n",
    "        # 融合时间与标签信息\n",
    "        combined = torch.cat([t_emb, l_emb], dim=1)\n",
    "        return self.fusion(combined)    # [B, time_dim]\n"
   ],
   "id": "5367699186ccfdc9",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Group Norm",
   "id": "a2d7fc0dc6585e29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.592167900Z",
     "start_time": "2025-03-03T14:17:06.469352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.GroupNorm(1, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)"
   ],
   "id": "8a8793089f32892d",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 采样",
   "id": "791d9f9919d0e16e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.592167900Z",
     "start_time": "2025-03-03T14:17:06.498545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 上采样（反卷积）\n",
    "def Upsample(dim):\n",
    "    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "# 下采样\n",
    "def Downsample(dim):\n",
    "    return nn.Conv2d(dim, dim, 4, 2, 1)"
   ],
   "id": "ea7d1c8a3ca05b0a",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Attention",
   "id": "7fdde2cc298f8f21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.602566400Z",
     "start_time": "2025-03-03T14:17:06.525313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import einsum, softmax\n",
    "from einops import rearrange\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum(\"b\"\n",
    "                     \" h d i, b h d j -> b h i j\", q, k)\n",
    "        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n",
    "        attn = sim.softmax(dim=-1)\n",
    "\n",
    "        out = einsum(\"b h i j, b h d j -> b h i d\", attn, v)\n",
    "        out = rearrange(out, \"b h (x y) d -> b (h d) x y\", x=h, y=w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),\n",
    "                                    nn.GroupNorm(1, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "\n",
    "        q = q.softmax(dim=-2)\n",
    "        k = k.softmax(dim=-1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
    "\n",
    "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
    "        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n",
    "        return self.to_out(out)"
   ],
   "id": "c0b7d896fc10bee9",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.602566400Z",
     "start_time": "2025-03-03T14:17:06.566333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"通道注意力机制\"\"\"\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(channel // reduction, channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        avg_out = self.fc(self.avg_pool(x).view(b, c))\n",
    "        max_out = self.fc(self.max_pool(x).view(b, c))\n",
    "        out = avg_out + max_out\n",
    "        return x * out.view(b, c, 1, 1)"
   ],
   "id": "606ff3f7a5a9cc56",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Block",
   "id": "388056491833da36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.602566400Z",
     "start_time": "2025-03-03T14:17:06.611660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConvNextBlock(nn.Module):\n",
    "    \"\"\"A ConvNet for the 2020s\"\"\"\n",
    "\n",
    "    def __init__(self, in_ch, out_ch, time_embed_dim, mult=2, norm=True):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(nn.GELU(), nn.Linear(time_embed_dim, out_ch*2))\n",
    "\n",
    "        self.ds_conv = nn.Conv2d(in_ch, out_ch, 3, padding=1, groups=in_ch)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.GroupNorm(1, in_ch) if norm else nn.Identity(),\n",
    "            nn.Conv2d(in_ch, out_ch * mult, 3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.GroupNorm(1, out_ch * mult),\n",
    "            nn.Conv2d(out_ch * mult, out_ch, 3, padding=1),\n",
    "        )\n",
    "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        h = self.ds_conv(x)\n",
    "\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            condition = self.mlp(time_emb)\n",
    "            h = h + rearrange(condition, \"b c -> b c 1 1\")\n",
    "\n",
    "        h = self.net(h)\n",
    "        return h + self.res_conv(x)"
   ],
   "id": "281026067d56eef8",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.602566400Z",
     "start_time": "2025-03-03T14:17:06.636177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyBlock(nn.Module):\n",
    "    \"\"\"简化后的基础块（去除残差和注意力）\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, time_dim, mult = 1):\n",
    "        super().__init__()\n",
    "        # self.time_mlp = nn.Linear(time_dim, out_ch*2)\n",
    "        self.time_mlp = nn.Sequential(nn.GELU(), nn.Linear(time_dim, out_ch))\n",
    "\n",
    "        self.ds_conv = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.GroupNorm(1, out_ch),  # 原 in_ch 改为 out_ch !\n",
    "            nn.Conv2d(out_ch, out_ch * mult, 3, padding=1),  # 同步修改输入通道为 out_ch\n",
    "            nn.GELU(),\n",
    "            nn.GroupNorm(1, out_ch * mult),\n",
    "            nn.Conv2d(out_ch * mult, out_ch, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        h = self.ds_conv(x)\n",
    "        condition = self.time_mlp(t_emb)\n",
    "        h = h + rearrange(condition, \"b c -> b c 1 1\")\n",
    "        h = self.conv(h)\n",
    "        return h + self.res_conv(x)"
   ],
   "id": "8968aa5b9098fd9b",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.602566400Z",
     "start_time": "2025-03-03T14:17:06.658460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from einops import rearrange\n",
    "\n",
    "class ConditionalBlock(nn.Module):\n",
    "    \"\"\"基于你原有MyBlock改造的条件版本\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, cond_dim, mult=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cond_dim: 条件向量的维度 (time+label的融合维度)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 修改后的条件投影层（移除偏置项）验证条件注入的有效性\n",
    "        self.cond_mlp = nn.Sequential(\n",
    "            nn.Linear(cond_dim, out_ch*2, bias=False),  # 关键修改：bias=False\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        # 保持原有卷积结构\n",
    "        self.ds_conv = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.GroupNorm(1, out_ch),\n",
    "            nn.Conv2d(out_ch, out_ch * mult, 3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.GroupNorm(1, out_ch * mult),\n",
    "            nn.Conv2d(out_ch * mult, out_ch, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x, cond_emb):\n",
    "        \"\"\"输入变化：t_emb → cond_emb (融合时间+标签的条件向量)\"\"\"\n",
    "        h = self.ds_conv(x)\n",
    "\n",
    "        # 条件注入 (scale and shift)\n",
    "        scale, shift = self.cond_mlp(cond_emb).chunk(2, dim=1)  # [B, 2*out_ch] → [B, out_ch], [B, out_ch]\n",
    "        h = h * (1 + scale[:, :, None, None])  # 缩放\n",
    "        h = h + shift[:, :, None, None]        # 偏移\n",
    "\n",
    "        h = self.conv(h)\n",
    "        return h + self.res_conv(x)  # 保持原有残差连接\n"
   ],
   "id": "f2d99f324b00b884",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test_MyBlock",
   "id": "e40ec03d3a29f413"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.610321200Z",
     "start_time": "2025-03-03T14:17:06.695044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "def test_myblock():\n",
    "    # 测试配置\n",
    "    batch_size = 64\n",
    "    height, width = 24, 50\n",
    "    time_dim = 256\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # 测试案例配置\n",
    "    test_cases = [\n",
    "        {\"in_ch\": 32, \"out_ch\": 64, \"mult\": 1},\n",
    "        {\"in_ch\": 64, \"out_ch\": 128, \"mult\": 2},\n",
    "        {\"in_ch\": 128, \"out_ch\": 256, \"mult\": 4}\n",
    "    ]\n",
    "\n",
    "    for case in test_cases:\n",
    "        print(f\"\\n=== 测试配置: {case} ===\")\n",
    "\n",
    "        # 初始化模块\n",
    "        block = MyBlock(\n",
    "            in_ch=case[\"in_ch\"],\n",
    "            out_ch=case[\"out_ch\"],\n",
    "            time_dim=time_dim,\n",
    "            mult=case[\"mult\"]\n",
    "        ).to(device)\n",
    "\n",
    "        # 生成测试输入\n",
    "        x = torch.randn(batch_size, case[\"in_ch\"], height, width).to(device)\n",
    "        t_emb = torch.randn(batch_size, time_dim).to(device)\n",
    "\n",
    "        # 测试1: 前向传播形状\n",
    "        def test_shape():\n",
    "            output = block(x, t_emb)\n",
    "            expected_shape = (batch_size, case[\"out_ch\"], height, width)\n",
    "            assert output.shape == expected_shape, \\\n",
    "                f\"形状错误！期望: {expected_shape}, 实际: {output.shape}\"\n",
    "            print(\"✅ 前向传播形状测试通过\")\n",
    "\n",
    "        # 测试2: 梯度流\n",
    "        def test_gradient():\n",
    "            block.train()\n",
    "            x.requires_grad_(True)\n",
    "            output = block(x, t_emb)\n",
    "            loss = output.mean()\n",
    "            loss.backward()\n",
    "\n",
    "            # 检查输入梯度\n",
    "            assert x.grad is not None, \"输入梯度未生成\"\n",
    "            # 检查参数梯度\n",
    "            has_grad = any(p.grad is not None for p in block.parameters())\n",
    "            assert has_grad, \"参数未接收梯度\"\n",
    "            print(\"✅ 梯度流测试通过\")\n",
    "\n",
    "        # 测试3: 设备兼容性\n",
    "        def test_device():\n",
    "            cpu_block = MyBlock(**case, time_dim=time_dim).cpu()\n",
    "            cpu_x = x.cpu()\n",
    "            cpu_t = t_emb.cpu()\n",
    "            output = cpu_block(cpu_x, cpu_t)\n",
    "            assert output.device.type == \"cpu\", \"应生成CPU张量\"\n",
    "            print(\"✅ CPU兼容性测试通过\")\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_output = block(x, t_emb)\n",
    "                assert gpu_output.is_cuda, \"应生成CUDA张量\"\n",
    "                print(\"✅ GPU兼容性测试通过\")\n",
    "\n",
    "        # 执行测试\n",
    "        test_shape()\n",
    "        test_gradient()\n",
    "        test_device()"
   ],
   "id": "59a578c65027746a",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.612846900Z",
     "start_time": "2025-03-03T14:17:06.715606Z"
    }
   },
   "cell_type": "code",
   "source": "#test_myblock()",
   "id": "6464cc6f7ee1416",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test_ConditionalBlock",
   "id": "f5e8a15547e50a5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.614856500Z",
     "start_time": "2025-03-03T14:17:06.733874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "def test_conditional_myblock():\n",
    "    # 测试配置\n",
    "    batch_size = 4\n",
    "    height, width = 24, 50\n",
    "    cond_dim = 256  # 条件向量维度\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # 测试案例\n",
    "    test_cases = [\n",
    "        {\"in_ch\": 32, \"out_ch\": 64, \"mult\": 1},\n",
    "        {\"in_ch\": 64, \"out_ch\": 128, \"mult\": 2},\n",
    "        {\"in_ch\": 128, \"out_ch\": 256, \"mult\": 4}\n",
    "    ]\n",
    "\n",
    "    for case in test_cases:\n",
    "        print(f\"\\n=== 测试配置 {case} ===\")\n",
    "\n",
    "        # 初始化模块\n",
    "        block = ConditionalBlock(\n",
    "            in_ch=case[\"in_ch\"],\n",
    "            out_ch=case[\"out_ch\"],\n",
    "            cond_dim=cond_dim,\n",
    "            mult=case[\"mult\"]\n",
    "        ).to(device)\n",
    "\n",
    "        # 生成测试输入\n",
    "        x = torch.randn(batch_size, case[\"in_ch\"], height, width).to(device)\n",
    "        cond_emb = torch.randn(batch_size, cond_dim).to(device)\n",
    "\n",
    "        # 测试1: 前向传播形状\n",
    "        def test_shape():\n",
    "            output = block(x, cond_emb)\n",
    "            expected_shape = (batch_size, case[\"out_ch\"], height, width)\n",
    "            assert output.shape == expected_shape, \\\n",
    "                f\"形状错误！期望: {expected_shape}, 实际: {output.shape}\"\n",
    "            print(\"✅ 形状测试通过\")\n",
    "\n",
    "        # 测试2: 梯度流\n",
    "        def test_gradient():\n",
    "            block.train()\n",
    "            x.requires_grad_(True)\n",
    "            output = block(x, cond_emb)\n",
    "            loss = output.mean()\n",
    "            loss.backward()\n",
    "\n",
    "            # 检查输入梯度\n",
    "            assert x.grad is not None, \"输入梯度未生成\"\n",
    "            # 检查条件投影层梯度\n",
    "            assert block.cond_mlp[0].weight.grad is not None, \"条件投影层未更新\"\n",
    "            print(\"✅ 梯度测试通过\")\n",
    "\n",
    "        # 测试3: 条件注入有效性\n",
    "        def test_condition_effect():\n",
    "            # 相同输入不同条件\n",
    "            cond1 = torch.randn_like(cond_emb)\n",
    "            cond2 = torch.randn_like(cond_emb)\n",
    "\n",
    "            out1 = block(x, cond1)\n",
    "            out2 = block(x, cond2)\n",
    "\n",
    "            # 确保不同条件产生不同输出\n",
    "            assert not torch.allclose(out1, out2, atol=1e-6), \"条件未影响输出\"\n",
    "\n",
    "            # 零条件测试\n",
    "            zero_cond = torch.zeros_like(cond_emb)\n",
    "            out_zero = block(x, zero_cond)\n",
    "            scale, shift = block.cond_mlp(zero_cond).chunk(2, dim=1)\n",
    "\n",
    "            # 验证数学正确性：当条件为零时，h = h_conv + residual\n",
    "            h_conv = block.ds_conv(x)\n",
    "            expected = block.conv(h_conv) + block.res_conv(x)\n",
    "            assert torch.allclose(out_zero, expected, atol=1e-6), \"零条件计算错误\"\n",
    "            print(\"✅ 条件注入测试通过\")\n",
    "\n",
    "        # 测试4: 设备兼容性\n",
    "        def test_device():\n",
    "            cpu_block = ConditionalBlock(**case, cond_dim=cond_dim).cpu()\n",
    "            cpu_x = x.cpu()\n",
    "            cpu_cond = cond_emb.cpu()\n",
    "            output = cpu_block(cpu_x, cpu_cond)\n",
    "            assert output.device.type == \"cpu\", \"应生成CPU张量\"\n",
    "            print(\"✅ CPU兼容性测试通过\")\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_output = block(x, cond_emb)\n",
    "                assert gpu_output.is_cuda, \"应生成CUDA张量\"\n",
    "                print(\"✅ GPU兼容性测试通过\")\n",
    "\n",
    "        # 执行测试\n",
    "        test_shape()\n",
    "        test_gradient()\n",
    "        test_condition_effect()\n",
    "        test_device()"
   ],
   "id": "8ffc5ce01a3ae7db",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.616868600Z",
     "start_time": "2025-03-03T14:17:06.760374Z"
    }
   },
   "cell_type": "code",
   "source": "test_conditional_myblock()",
   "id": "4cead5f87becf3f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 测试配置 {'in_ch': 32, 'out_ch': 64, 'mult': 1} ===\n",
      "✅ 形状测试通过\n",
      "✅ 梯度测试通过\n",
      "✅ 条件注入测试通过\n",
      "✅ CPU兼容性测试通过\n",
      "\n",
      "=== 测试配置 {'in_ch': 64, 'out_ch': 128, 'mult': 2} ===\n",
      "✅ 形状测试通过\n",
      "✅ 梯度测试通过\n",
      "✅ 条件注入测试通过\n",
      "✅ CPU兼容性测试通过\n",
      "\n",
      "=== 测试配置 {'in_ch': 128, 'out_ch': 256, 'mult': 4} ===\n",
      "✅ 形状测试通过\n",
      "✅ 梯度测试通过\n",
      "✅ 条件注入测试通过\n",
      "✅ CPU兼容性测试通过\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Residual",
   "id": "74bd9666b1267b5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.616868600Z",
     "start_time": "2025-03-03T14:17:08.233092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 残差模块，将输入加到输出上\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x"
   ],
   "id": "903109ea569148b3",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### U-net",
   "id": "58f0fc86318986e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.620405200Z",
     "start_time": "2025-03-03T14:17:08.273614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EnhancedDiffusionUNet(nn.Module):\n",
    "    def __init__(self, time_dim=128):\n",
    "        super().__init__()\n",
    "        chs = [1, 64, 128, 256]\n",
    "\n",
    "        self.time_embed = EnhancedTimeEmbedding(time_dim)\n",
    "\n",
    "        # 下采样路径\n",
    "        self.down = nn.ModuleList([\n",
    "            MySequential(\n",
    "                MyBlock(chs[i], chs[i+1], time_dim*4),\n",
    "                MyBlock(chs[i+1], chs[i+1], time_dim*4),\n",
    "                #ChannelAttention(chs[i+1])\n",
    "                Residual(PreNorm(chs[i+1], LinearAttention(chs[i+1])))\n",
    "            ) for i in range(len(chs)-1)\n",
    "        ])\n",
    "\n",
    "        # 中间层\n",
    "        self.mid = MySequential(\n",
    "            MyBlock(chs[-1], chs[-1], time_dim*4),\n",
    "            #ChannelAttention(chs[-1]),\n",
    "            Residual(PreNorm(chs[-1], Attention(chs[-1]))),\n",
    "            MyBlock(chs[-1], chs[-1], time_dim*4)\n",
    "        )\n",
    "\n",
    "        # 上采样路径\n",
    "        self.up = nn.ModuleList([\n",
    "            MySequential(\n",
    "                MyBlock(chs[i+1]*2, chs[i], time_dim*4),\n",
    "                MyBlock(chs[i], chs[i], time_dim*4),\n",
    "                #ChannelAttention(chs[i])\n",
    "                Residual(PreNorm(chs[i], LinearAttention(chs[i])))\n",
    "            ) for i in reversed(range(len(chs)-1))\n",
    "        ])\n",
    "\n",
    "        self.final = nn.Conv2d(chs[0], 1, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = x.unsqueeze(1)  # [B,1,24,50]\n",
    "        t_emb = self.time_embed(t)\n",
    "        skips = []\n",
    "\n",
    "        # 编码器\n",
    "        for block in self.down:\n",
    "            x = block(x, t_emb)\n",
    "            skips.append(x)\n",
    "            x = F.max_pool2d(x, kernel_size=(2,1))\n",
    "\n",
    "        # 中间处理\n",
    "        x = self.mid(x, t_emb)\n",
    "\n",
    "        # 解码器\n",
    "        for i, block in enumerate(self.up):\n",
    "            x = F.interpolate(x, scale_factor=(2,1), mode='nearest')\n",
    "            x = torch.cat([x, skips[-(i+1)]], dim=1)\n",
    "            x = block(x, t_emb)\n",
    "\n",
    "        return self.final(x).squeeze(1)"
   ],
   "id": "ba38ffef6fa22b3b",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test_U-net",
   "id": "629b74e8f580af6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.623017800Z",
     "start_time": "2025-03-03T14:17:08.292026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_diffusion_unet():\n",
    "    # 配置测试参数\n",
    "    batch_size = 64\n",
    "    input_shape = (24, 50)  # 你的数据维度\n",
    "    timesteps = 200\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # 初始化模型\n",
    "    model = EnhancedDiffusionUNet(time_dim=128).to(device)\n",
    "\n",
    "    # 测试案例1: 基础前向传播\n",
    "    def test_forward_pass():\n",
    "        # 生成模拟输入\n",
    "        x = torch.randn(batch_size, *input_shape).to(device)  # [64,24,50]\n",
    "        t = torch.randint(0, timesteps, (batch_size,)).to(device)  # 时间步\n",
    "        # 前向传播\n",
    "        output = model(x, t)\n",
    "\n",
    "        # 验证输出形状\n",
    "        assert output.shape == (batch_size, *input_shape), \\\n",
    "            f\"输出形状错误！期望: {(batch_size, *input_shape)}, 实际: {output.shape}\"\n",
    "\n",
    "        print(\"✅ 前向传播测试通过\")\n",
    "\n",
    "    # 测试案例2: 设备兼容性\n",
    "    def test_device_compatibility():\n",
    "        cpu_model = EnhancedDiffusionUNet(time_dim=128).cpu()\n",
    "        x_cpu = torch.randn(batch_size, *input_shape).cpu()\n",
    "        t_cpu = torch.randint(0, timesteps, (batch_size,)).cpu()\n",
    "\n",
    "        output_cpu = cpu_model(x_cpu, t_cpu)\n",
    "        assert not output_cpu.is_cuda, \"CPU模型不应产生GPU张量\"\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_output = model(x_cpu.to(device), t_cpu.to(device))\n",
    "            assert gpu_output.is_cuda, \"GPU模型应产生CUDA张量\"\n",
    "\n",
    "        print(\"✅ 设备兼容性测试通过\")\n",
    "\n",
    "    # 测试案例3: 梯度检查\n",
    "    def test_gradient_flow():\n",
    "        model.train()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        x = torch.randn(batch_size, *input_shape).to(device)\n",
    "        t = torch.randint(0, timesteps, (batch_size,)).to(device)\n",
    "        target = torch.randn_like(x)\n",
    "\n",
    "        # 模拟训练步骤\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x, t)\n",
    "        loss = F.mse_loss(pred, target)\n",
    "        loss.backward()\n",
    "\n",
    "        # 检查梯度是否存在\n",
    "        has_gradients = any(p.grad is not None for p in model.parameters())\n",
    "        assert has_gradients, \"模型参数未接收到梯度\"\n",
    "\n",
    "        print(\"✅ 梯度流测试通过\")\n",
    "\n",
    "    # 执行测试\n",
    "    print(\"=== 开始Diffusion U-Net测试 ===\")\n",
    "    test_forward_pass()\n",
    "    test_device_compatibility()\n",
    "    test_gradient_flow()\n",
    "    print(\"=== 所有测试通过 ===\")"
   ],
   "id": "23d7d38391bb7b16",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.623017800Z",
     "start_time": "2025-03-03T14:17:08.314149Z"
    }
   },
   "cell_type": "code",
   "source": "#test_diffusion_unet()",
   "id": "d693522f964cc1fd",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Conditional U-Net",
   "id": "2e219e8e43dca23c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.623017800Z",
     "start_time": "2025-03-03T14:17:08.331582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConditionalDiffusionUNet(nn.Module):\n",
    "    def __init__(self, num_classes, time_dim=128, label_dim=64):\n",
    "        super().__init__()\n",
    "        chs = [1, 64, 128, 256]\n",
    "\n",
    "        # 替换为条件嵌入层\n",
    "        self.cond_embed = ConditionalEmbedding(\n",
    "            num_classes=num_classes,\n",
    "            time_dim=time_dim,\n",
    "            label_dim=label_dim\n",
    "        )\n",
    "        cond_dim = time_dim  # 条件向量的总维度\n",
    "\n",
    "        # 下采样路径（修改所有MyBlock的cond_dim）\n",
    "        self.down = nn.ModuleList([\n",
    "            MySequential(\n",
    "                ConditionalBlock(chs[i], chs[i+1], cond_dim=cond_dim),\n",
    "                ConditionalBlock(chs[i+1], chs[i+1], cond_dim=cond_dim),\n",
    "                Residual(PreNorm(chs[i+1], LinearAttention(chs[i+1])))\n",
    "            ) for i in range(len(chs)-1)\n",
    "        ])\n",
    "\n",
    "        # 中间层\n",
    "        self.mid = MySequential(\n",
    "            ConditionalBlock(chs[-1], chs[-1], cond_dim=cond_dim),\n",
    "            Residual(PreNorm(chs[-1], Attention(chs[-1]))),\n",
    "            ConditionalBlock(chs[-1], chs[-1], cond_dim=cond_dim)\n",
    "        )\n",
    "\n",
    "        # 上采样路径\n",
    "        self.up = nn.ModuleList([\n",
    "            MySequential(\n",
    "                ConditionalBlock(chs[i+1]*2, chs[i], cond_dim=cond_dim),\n",
    "                ConditionalBlock(chs[i], chs[i], cond_dim=cond_dim),\n",
    "                Residual(PreNorm(chs[i], LinearAttention(chs[i])))\n",
    "            ) for i in reversed(range(len(chs)-1))\n",
    "        ])\n",
    "\n",
    "        self.final = nn.Conv2d(chs[0], 1, 1)\n",
    "\n",
    "    def forward(self, x, t, y):\n",
    "        \"\"\"新增标签y作为输入\"\"\"\n",
    "        x = x.unsqueeze(1)  # [B,1,24,50]\n",
    "\n",
    "        cond_emb = self.cond_embed(t, y)  # 获取融合条件向量\n",
    "        skips = []\n",
    "\n",
    "        # 编码器（传递cond_emb）\n",
    "        for block in self.down:\n",
    "            x = block(x, cond_emb)\n",
    "            skips.append(x)\n",
    "            x = F.max_pool2d(x, kernel_size=(2,1))\n",
    "\n",
    "        # 中间处理\n",
    "        x = self.mid(x, cond_emb)\n",
    "\n",
    "        # 解码器\n",
    "        for i, block in enumerate(self.up):\n",
    "            x = F.interpolate(x, scale_factor=(2,1), mode='nearest')\n",
    "            x = torch.cat([x, skips[-(i+1)]], dim=1)\n",
    "            x = block(x, cond_emb)\n",
    "\n",
    "        return self.final(x).squeeze(1)\n"
   ],
   "id": "e2eb99587be3c918",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test Conditional U-net",
   "id": "51277114bc17099e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.623017800Z",
     "start_time": "2025-03-03T14:17:08.354302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_conditional_diffusion_unet():\n",
    "    # 配置测试参数\n",
    "    batch_size = 32\n",
    "    input_shape = (24, 50)    # 输入数据维度\n",
    "    num_classes = 10          # 类别数量\n",
    "    timesteps = 1000          # 扩散步数\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # 初始化条件模型\n",
    "    model = ConditionalDiffusionUNet(\n",
    "        num_classes=num_classes,\n",
    "        time_dim=128,\n",
    "        label_dim=64\n",
    "    ).to(device)\n",
    "\n",
    "    # 测试案例1: 基础前向传播\n",
    "    def test_forward_pass():\n",
    "        # 生成模拟输入（注意标签维度）\n",
    "        x = torch.randn(batch_size, *input_shape).to(device)  # [32,24,50]\n",
    "        t = torch.randint(0, timesteps, (batch_size,)).to(device)\n",
    "        y = torch.randint(0, num_classes, (batch_size,)).to(device)  # 关键：一维标签\n",
    "\n",
    "        # 前向传播\n",
    "        output = model(x, t, y)\n",
    "\n",
    "        # 验证输出形状\n",
    "        assert output.shape == x.shape, \\\n",
    "            f\"形状不匹配！输入: {x.shape}, 输出: {output.shape}\"\n",
    "        print(\"✅ 前向传播测试通过\")\n",
    "\n",
    "    # 测试案例2: 设备兼容性\n",
    "    def test_device_compatibility():\n",
    "        # CPU测试\n",
    "        cpu_model = ConditionalDiffusionUNet(num_classes=num_classes).cpu()\n",
    "        x_cpu = torch.randn(batch_size, *input_shape).cpu()\n",
    "        t_cpu = torch.randint(0, timesteps, (batch_size,)).cpu()\n",
    "        y_cpu = torch.randint(0, num_classes, (batch_size,)).cpu()\n",
    "\n",
    "        output_cpu = cpu_model(x_cpu, t_cpu, y_cpu)\n",
    "        assert output_cpu.device.type == \"cpu\", \"CPU模型应生成CPU张量\"\n",
    "\n",
    "        # GPU测试（如果可用）\n",
    "        if torch.cuda.is_available():\n",
    "            output_gpu = model(x_cpu.to(device), t_cpu.to(device), y_cpu.to(device))\n",
    "            assert output_gpu.is_cuda, \"GPU模型应生成CUDA张量\"\n",
    "        print(\"✅ 设备兼容性测试通过\")\n",
    "\n",
    "    # 测试案例3: 梯度流检查\n",
    "    def test_gradient_flow():\n",
    "        model.train()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        # 生成模拟数据\n",
    "        x = torch.randn(batch_size, *input_shape).to(device)\n",
    "        t = torch.randint(0, timesteps, (batch_size,)).to(device)\n",
    "        y = torch.randint(0, num_classes, (batch_size,)).to(device)\n",
    "        target = torch.randn_like(x)\n",
    "\n",
    "        # 模拟训练步骤\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x, t, y)\n",
    "        loss = F.mse_loss(pred, target)\n",
    "        loss.backward()\n",
    "\n",
    "        # 检查关键层梯度\n",
    "        assert model.cond_embed.label_embed.weight.grad is not None, \"标签嵌入层无梯度\"\n",
    "        assert model.down[0][0].cond_mlp[0].weight.grad is not None, \"条件投影层无梯度\"\n",
    "        assert model.final.weight.grad is not None, \"输出层无梯度\"\n",
    "        print(\"✅ 梯度流测试通过\")\n",
    "\n",
    "    # 测试案例4: 条件有效性\n",
    "    def test_condition_effectiveness():\n",
    "        # 固定输入和时间步\n",
    "        x = torch.randn(1, *input_shape).to(device)\n",
    "        t = torch.randint(0, timesteps, (1,)).to(device)\n",
    "\n",
    "        # 测试不同标签\n",
    "        y1 = torch.tensor([3], device=device)\n",
    "        y2 = torch.tensor([7], device=device)\n",
    "        out1 = model(x, t, y1)\n",
    "        out2 = model(x, t, y2)\n",
    "        assert not torch.allclose(out1, out2, atol=1e-6), \"不同标签应产生不同输出\"\n",
    "\n",
    "        # 测试不同时间步\n",
    "        t1 = torch.tensor([200], device=device)\n",
    "        t2 = torch.tensor([800], device=device)\n",
    "        out3 = model(x, t1, y1)\n",
    "        out4 = model(x, t2, y1)\n",
    "        assert not torch.allclose(out3, out4, atol=1e-6), \"不同时间步应产生不同输出\"\n",
    "        print(\"✅ 条件有效性测试通过\")\n",
    "\n",
    "    # 测试案例5: 极端输入稳定性\n",
    "    def test_extreme_inputs():\n",
    "        # 零输入测试\n",
    "        x_zero = torch.zeros(batch_size, *input_shape).to(device)\n",
    "        t = torch.randint(0, timesteps, (batch_size,)).to(device)\n",
    "        y = torch.randint(0, num_classes, (batch_size,)).to(device)\n",
    "        output = model(x_zero, t, y)\n",
    "        assert not torch.isnan(output).any(), \"零输入产生NaN\"\n",
    "\n",
    "        # 极大值输入\n",
    "        x_large = 1e5 * torch.randn_like(x_zero)\n",
    "        output = model(x_large, t, y)\n",
    "        assert not torch.isinf(output).any(), \"极大输入产生Inf\"\n",
    "        print(\"✅ 极端输入测试通过\")\n",
    "\n",
    "    # 执行所有测试\n",
    "    print(\"\\n=== 开始条件扩散U-Net测试 ===\")\n",
    "    test_forward_pass()\n",
    "    test_device_compatibility()\n",
    "    test_gradient_flow()\n",
    "    test_condition_effectiveness()\n",
    "    test_extreme_inputs()\n",
    "    print(\"=== 所有测试通过 ===\")"
   ],
   "id": "aa75a46abc9a269f",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.623017800Z",
     "start_time": "2025-03-03T14:17:08.382595Z"
    }
   },
   "cell_type": "code",
   "source": "test_conditional_diffusion_unet()",
   "id": "7d9b697356edbb44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 开始条件扩散U-Net测试 ===\n",
      "✅ 前向传播测试通过\n",
      "✅ 设备兼容性测试通过\n",
      "✅ 梯度流测试通过\n",
      "✅ 条件有效性测试通过\n",
      "✅ 极端输入测试通过\n",
      "=== 所有测试通过 ===\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### sample",
   "id": "e67deb24b8875647"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.623017800Z",
     "start_time": "2025-03-03T14:17:14.669571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def p_sample_cond(model, x, t, t_index, y):\n",
    "    \"\"\"带条件标签的单步去噪采样\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # 添加通道维度并传入标签y\n",
    "        pred_noise = model(x, t, y).squeeze(1)  # [B,24,50]\n",
    "\n",
    "    # 调整系数维度\n",
    "    sqrt_recip_alphas_t = (1 / torch.sqrt(alphas[t])).view(-1, 1, 1)  # [64] -> [64, 1, 1]\n",
    "    sqrt_one_minus_alphas_bar_t = extract(one_minus_alphas_bar_sqrt, t, x.shape)\n",
    "\n",
    "    # 去噪计算\n",
    "    x_recon = sqrt_recip_alphas_t * (x - pred_noise * sqrt_one_minus_alphas_bar_t)\n",
    "\n",
    "    if t_index > 0:\n",
    "        noise = torch.randn_like(x)\n",
    "        sqrt_beta_t = extract(torch.sqrt(betas), t, x.shape)\n",
    "        x_recon += sqrt_beta_t * noise\n",
    "\n",
    "    return x_recon\n"
   ],
   "id": "4886ac8f98102ce0",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.633523Z",
     "start_time": "2025-03-03T14:17:14.694017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def p_sample_loop_cond(model, shape, y, device='cuda'):\n",
    "    \"\"\"带标签的完整采样循环\"\"\"\n",
    "    # 初始化噪声和标签处理\n",
    "    img = torch.randn(shape, device=device)  # [B,24,50]\n",
    "    y = y.to(device)  # 标签需与模型同设备\n",
    "\n",
    "    # 反向时间步采样\n",
    "    for i in reversed(range(0, num_steps)):\n",
    "        t = torch.full((shape[0],), i, device=device, dtype=torch.long)\n",
    "        img = p_sample_cond(model, img, t, i, y)\n",
    "\n",
    "    return img\n"
   ],
   "id": "8b2bf55f3f34ce54",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.633523Z",
     "start_time": "2025-03-03T14:17:14.728868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_conditional_samples(\n",
    "    model,\n",
    "    num_samples=16,\n",
    "    labels=None,  # 可指定标签 [num_samples]\n",
    "    num_classes=7,  # 你的数据类别数\n",
    "    device='cuda'\n",
    "):\n",
    "    \"\"\"条件样本生成入口\"\"\"\n",
    "    # 标签处理逻辑\n",
    "    if labels is None:\n",
    "        # 随机生成标签\n",
    "        labels = torch.randint(0, num_classes, (num_samples,))\n",
    "    else:\n",
    "        assert len(labels) == num_samples, \"标签数量需与样本数一致\"\n",
    "\n",
    "    # 输入形状 [B,24,50]\n",
    "    sample_shape = (num_samples, 24, 50)\n",
    "\n",
    "    model.eval()\n",
    "    samples = p_sample_loop_cond(\n",
    "        model,\n",
    "        shape=sample_shape,\n",
    "        y=labels,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # 后处理\n",
    "    samples = samples.cpu().numpy()\n",
    "    samples = np.clip(samples, -1, 1)  # 根据你的数据归一化范围调整\n",
    "\n",
    "    return samples, labels\n"
   ],
   "id": "c5ca033d672ef5c6",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test_p_sample",
   "id": "e413910f95be6e68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.633523Z",
     "start_time": "2025-03-03T14:17:14.773950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_conditional_generation():\n",
    "    # 设置设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"测试设备: {device}\")\n",
    "\n",
    "    # 初始化模型 (参数需与训练时一致)\n",
    "    num_classes = 7  # 根据你的数据集调整\n",
    "    model = ConditionalDiffusionUNet(\n",
    "        num_classes=num_classes,\n",
    "        time_dim=128,\n",
    "        label_dim=64\n",
    "    ).to(device)\n",
    "\n",
    "    # 打印模型结构\n",
    "    print(\"\\n模型结构:\")\n",
    "    print(model)\n",
    "\n",
    "    # 测试用例1: 随机生成不同类别的样本\n",
    "    print(\"\\n测试用例1: 随机生成样本\")\n",
    "    samples, labels = generate_conditional_samples(\n",
    "        model,\n",
    "        num_samples=4,  # 生成4个样本\n",
    "        num_classes=num_classes,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # 验证输出形状\n",
    "    assert samples.shape == (4, 24, 50), f\"样本形状错误: 期望 (4,24,50)，实际 {samples.shape}\"\n",
    "    assert labels.shape == (4,), f\"标签形状错误: 期望 (4,)，实际 {labels.shape}\"\n",
    "    print(f\"生成样本形状: {samples.shape} | 标签形状: {labels.shape}\")\n",
    "\n",
    "    # 验证数据范围\n",
    "    assert samples.min() >= -1 and samples.max() <= 1, \"样本数据范围超出 [-1, 1]\"\n",
    "    print(f\"数据范围验证通过: min={samples.min():.2f}, max={samples.max():.2f}\")\n",
    "\n",
    "    # 测试用例2: 指定特定标签生成\n",
    "    print(\"\\n测试用例2: 指定标签生成\")\n",
    "    target_labels = torch.tensor([0, 1, 2, 3])  # 生成4个不同类别的样本\n",
    "    samples, labels = generate_conditional_samples(\n",
    "        model,\n",
    "        num_samples=4,\n",
    "        labels=target_labels,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # 验证标签匹配\n",
    "    assert (labels == target_labels).all(), \"生成标签与指定标签不匹配\"\n",
    "    print(f\"标签匹配验证通过: {labels.tolist()}\")\n",
    "\n",
    "    # 可视化第一个样本\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(samples[0], cmap='viridis', aspect='auto')\n",
    "    plt.title(f\"生成样本示例 (类别={labels[0]})\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ],
   "id": "32626b703f82a81",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:25.633523Z",
     "start_time": "2025-03-03T14:17:14.806732Z"
    }
   },
   "cell_type": "code",
   "source": "test_conditional_generation()",
   "id": "239603b64d07cfd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试设备: cpu\n",
      "\n",
      "模型结构:\n",
      "ConditionalDiffusionUNet(\n",
      "  (cond_embed): ConditionalEmbedding(\n",
      "    (time_embed): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (1): SiLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (label_embed): Embedding(7, 64)\n",
      "    (fusion): Sequential(\n",
      "      (0): Linear(in_features=576, out_features=256, bias=True)\n",
      "      (1): SiLU()\n",
      "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (down): ModuleList(\n",
      "    (0): MySequential(\n",
      "      (0): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttention(\n",
      "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): MySequential(\n",
      "      (0): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttention(\n",
      "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): MySequential(\n",
      "      (0): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=512, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=512, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttention(\n",
      "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mid): MySequential(\n",
      "    (0): ConditionalBlock(\n",
      "      (cond_mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=False)\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "      (ds_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv): Sequential(\n",
      "        (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (res_conv): Identity()\n",
      "    )\n",
      "    (1): Residual(\n",
      "      (fn): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (to_out): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ConditionalBlock(\n",
      "      (cond_mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=512, bias=False)\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "      (ds_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv): Sequential(\n",
      "        (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (res_conv): Identity()\n",
      "    )\n",
      "  )\n",
      "  (up): ModuleList(\n",
      "    (0): MySequential(\n",
      "      (0): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttention(\n",
      "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): MySequential(\n",
      "      (0): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttention(\n",
      "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): MySequential(\n",
      "      (0): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConditionalBlock(\n",
      "        (cond_mlp): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2, bias=False)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (ds_conv): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttention(\n",
      "            (to_qkv): Conv2d(1, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "\n",
      "测试用例1: 随机生成样本\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[72]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtest_conditional_generation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[71]\u001B[39m\u001B[32m, line 20\u001B[39m, in \u001B[36mtest_conditional_generation\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     18\u001B[39m \u001B[38;5;66;03m# 测试用例1: 随机生成不同类别的样本\u001B[39;00m\n\u001B[32m     19\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m测试用例1: 随机生成样本\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m samples, labels = \u001B[43mgenerate_conditional_samples\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 生成4个样本\u001B[39;49;00m\n\u001B[32m     23\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     24\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\n\u001B[32m     25\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[38;5;66;03m# 验证输出形状\u001B[39;00m\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m samples.shape == (\u001B[32m4\u001B[39m, \u001B[32m24\u001B[39m, \u001B[32m50\u001B[39m), \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m样本形状错误: 期望 (4,24,50)，实际 \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msamples.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[70]\u001B[39m\u001B[32m, line 20\u001B[39m, in \u001B[36mgenerate_conditional_samples\u001B[39m\u001B[34m(model, num_samples, labels, num_classes, device)\u001B[39m\n\u001B[32m     17\u001B[39m sample_shape = (num_samples, \u001B[32m24\u001B[39m, \u001B[32m50\u001B[39m)\n\u001B[32m     19\u001B[39m model.eval()\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m samples = \u001B[43mp_sample_loop_cond\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[43m    \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m=\u001B[49m\u001B[43msample_shape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     24\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\n\u001B[32m     25\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[38;5;66;03m# 后处理\u001B[39;00m\n\u001B[32m     28\u001B[39m samples = samples.cpu().numpy()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    113\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[69]\u001B[39m\u001B[32m, line 11\u001B[39m, in \u001B[36mp_sample_loop_cond\u001B[39m\u001B[34m(model, shape, y, device)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mreversed\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, num_steps)):\n\u001B[32m     10\u001B[39m     t = torch.full((shape[\u001B[32m0\u001B[39m],), i, device=device, dtype=torch.long)\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m     img = \u001B[43mp_sample_cond\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[68]\u001B[39m\u001B[32m, line 5\u001B[39m, in \u001B[36mp_sample_cond\u001B[39m\u001B[34m(model, x, t, t_index, y)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"带条件标签的单步去噪采样\"\"\"\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m      4\u001B[39m     \u001B[38;5;66;03m# 添加通道维度并传入标签y\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     pred_noise = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m.squeeze(\u001B[32m1\u001B[39m)  \u001B[38;5;66;03m# [B,24,50]\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# 调整系数维度\u001B[39;00m\n\u001B[32m      8\u001B[39m sqrt_recip_alphas_t = (\u001B[32m1\u001B[39m / torch.sqrt(alphas[t])).view(-\u001B[32m1\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m1\u001B[39m)  \u001B[38;5;66;03m# [64] -> [64, 1, 1]\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[65]\u001B[39m\u001B[32m, line 61\u001B[39m, in \u001B[36mConditionalDiffusionUNet.forward\u001B[39m\u001B[34m(self, x, t, y)\u001B[39m\n\u001B[32m     59\u001B[39m     x = F.interpolate(x, scale_factor=(\u001B[32m2\u001B[39m,\u001B[32m1\u001B[39m), mode=\u001B[33m'\u001B[39m\u001B[33mnearest\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     60\u001B[39m     x = torch.cat([x, skips[-(i+\u001B[32m1\u001B[39m)]], dim=\u001B[32m1\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m     x = \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcond_emb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     63\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.final(x).squeeze(\u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[45]\u001B[39m\u001B[32m, line 9\u001B[39m, in \u001B[36mMySequential.forward\u001B[39m\u001B[34m(self, x, t_emb)\u001B[39m\n\u001B[32m      7\u001B[39m         x = module(x, t_emb)\n\u001B[32m      8\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# 其他模块按默认方式处理\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m         x = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[61]\u001B[39m\u001B[32m, line 8\u001B[39m, in \u001B[36mResidual.forward\u001B[39m\u001B[34m(self, x, *args, **kwargs)\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, *args, **kwargs):\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m + x\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[50]\u001B[39m\u001B[32m, line 8\u001B[39m, in \u001B[36mPreNorm.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnorm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.fn(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:313\u001B[39m, in \u001B[36mGroupNorm.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    312\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m313\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgroup_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnum_groups\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\miniconda3\\envs\\guided_diffusion\\Lib\\site-packages\\torch\\nn\\functional.py:2965\u001B[39m, in \u001B[36mgroup_norm\u001B[39m\u001B[34m(input, num_groups, weight, bias, eps)\u001B[39m\n\u001B[32m   2958\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   2959\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExpected at least 2 dimensions for input tensor but received \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m.dim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   2960\u001B[39m     )\n\u001B[32m   2961\u001B[39m _verify_batch_size(\n\u001B[32m   2962\u001B[39m     [\u001B[38;5;28minput\u001B[39m.size(\u001B[32m0\u001B[39m) * \u001B[38;5;28minput\u001B[39m.size(\u001B[32m1\u001B[39m) // num_groups, num_groups]\n\u001B[32m   2963\u001B[39m     + \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28minput\u001B[39m.size()[\u001B[32m2\u001B[39m:])\n\u001B[32m   2964\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m2965\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgroup_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2966\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_groups\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackends\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcudnn\u001B[49m\u001B[43m.\u001B[49m\u001B[43menabled\u001B[49m\n\u001B[32m   2967\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 训练流程",
   "id": "5a01ae8c7ff43ab0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def q_sample(x0, t, noise):\n",
    "    \"\"\"前向扩散过程：根据时间步t给x0加噪\"\"\"\n",
    "    sqrt_alpha_prod = torch.sqrt(alphas_prod[t]).view(-1, 1, 1)\n",
    "    sqrt_one_minus_alpha_prod = torch.sqrt(1 - alphas_prod[t]).view(-1, 1, 1)\n",
    "    return sqrt_alpha_prod * x0 + sqrt_one_minus_alpha_prod * noise\n",
    "\n",
    "def train_conditional_diffusion():\n",
    "    # 超参数配置\n",
    "    config = {\n",
    "        \"batch_size\": 64,\n",
    "        \"lr\": 2e-4,\n",
    "        \"epochs\": 1000,\n",
    "        \"num_samples\": 8,        # 验证时生成的样本数\n",
    "        \"save_interval\": 100,     # 保存间隔（epoch）\n",
    "        \"grad_clip\": 1.0,         # 梯度裁剪阈值\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    }\n",
    "\n",
    "    # 准备数据集\n",
    "    dataset = TensorDataset(x0, labels)  # x0: [N,24,50], labels: [N]\n",
    "    dataloader = DataLoader(dataset,\n",
    "                          batch_size=config[\"batch_size\"],\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True)\n",
    "\n",
    "    # 初始化模型\n",
    "    model = ConditionalDiffusionUNet(\n",
    "        num_classes=num_classes,\n",
    "        time_dim=128,\n",
    "        label_dim=64\n",
    "    ).to(config[\"device\"])\n",
    "\n",
    "    # 优化器与学习率调度\n",
    "    optimizer = AdamW(model.parameters(), lr=config[\"lr\"])\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config[\"epochs\"])\n",
    "\n",
    "    # 训练循环\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(1, config[\"epochs\"]+1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "        for batch_x0, batch_labels in pbar:\n",
    "            # 数据准备\n",
    "            batch_x0 = batch_x0.to(config[\"device\"])  # [B,24,50]\n",
    "            batch_labels = batch_labels.to(config[\"device\"])  # [B]\n",
    "\n",
    "            # 随机采样时间步\n",
    "            b = batch_x0.size(0)\n",
    "            t = torch.randint(0, num_steps, (b,), device=config[\"device\"])\n",
    "\n",
    "            # 生成噪声\n",
    "            noise = torch.randn_like(batch_x0)\n",
    "\n",
    "            # 前向扩散\n",
    "            xt = q_sample(batch_x0, t, noise)\n",
    "\n",
    "            # 模型预测\n",
    "            pred_noise = model(xt, t, batch_labels)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = F.mse_loss(pred_noise, noise)\n",
    "\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config[\"grad_clip\"])\n",
    "            optimizer.step()\n",
    "\n",
    "            # 记录损失\n",
    "            epoch_loss += loss.item() * b\n",
    "            pbar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "\n",
    "        # 计算平均损失\n",
    "        epoch_loss /= len(dataset)\n",
    "        print(f\"Epoch {epoch} | Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # 保存最佳模型\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), \"best_conditional_diffusion.pth\")\n",
    "\n",
    "        # 定期采样验证\n",
    "        if epoch % config[\"save_interval\"] == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # 生成每个类别的样本\n",
    "                for label in range(num_classes):\n",
    "                    samples = generate_class_samples(\n",
    "                        model=model,\n",
    "                        num_samples=config[\"num_samples\"],\n",
    "                        label=label,\n",
    "                        device=config[\"device\"]\n",
    "                    )\n",
    "                    save_samples(samples, f\"epoch{epoch}_class{label}.npy\")\n",
    "\n",
    "            # 保存检查点\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"loss\": epoch_loss\n",
    "            }, f\"checkpoint_epoch{epoch}.pth\")\n",
    "\n",
    "def generate_class_samples(model, num_samples, label, device):\n",
    "    \"\"\"生成指定类别的样本\"\"\"\n",
    "    model.eval()\n",
    "    labels = torch.full((num_samples,), label, device=device)\n",
    "    shape = (num_samples, 24, 50)\n",
    "\n",
    "    # 初始噪声\n",
    "    xt = torch.randn(shape, device=device)\n",
    "\n",
    "    # 迭代去噪\n",
    "    for t in reversed(range(num_steps)):\n",
    "        timesteps = torch.full((num_samples,), t, device=device, dtype=torch.long)\n",
    "        xt = p_sample(model, xt, timesteps, labels)\n",
    "\n",
    "    # 后处理\n",
    "    samples = xt.cpu().numpy()\n",
    "    samples = (samples - samples.min()) / (samples.max() - samples.min())  # 归一化到[0,1]\n",
    "    return samples\n",
    "\n",
    "def p_sample(model, xt, t, y):\n",
    "    \"\"\"单步去噪采样\"\"\"\n",
    "    alpha_t = extract(alphas, t, xt.shape)\n",
    "    beta_t = extract(betas, t, xt.shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_noise = model(xt, t, y)\n",
    "\n",
    "    # 计算去噪结果\n",
    "    noise = torch.randn_like(xt) if t[0] > 0 else 0\n",
    "    xt_prev = 1 / torch.sqrt(alpha_t) * (\n",
    "        xt - (beta_t / torch.sqrt(1 - alphas_prod[t])) * pred_noise\n",
    "    ) + torch.sqrt(beta_t) * noise\n",
    "\n",
    "    return xt_prev\n",
    "\n",
    "def save_samples(samples, filename):\n",
    "    \"\"\"保存样本到文件\"\"\"\n",
    "    np.save(filename, samples)\n",
    "    print(f\"Saved samples to {filename}\")"
   ],
   "id": "a865f41b530fd340"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#train_conditional_diffusion()",
   "id": "64fd077008a29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
